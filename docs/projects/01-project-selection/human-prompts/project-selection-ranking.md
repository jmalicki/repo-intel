# Project Selection and Ranking Prompt

**Task:** Final project selection and ranking decisions
**Context:** Review automated metrics and apply human judgment for final selection

## Pre-Review Checklist

- [ ] Automated metrics have been collected for all candidates
- [ ] Quantitative scores have been calculated
- [ ] Initial filtering has been applied
- [ ] Data is ready for human review

## Evaluation Framework

### 1. Quality Assessment (40% weight)

**Code Quality Indicators:**
- [ ] Well-organized codebase structure
- [ ] Clear separation of concerns
- [ ] Consistent coding patterns
- [ ] Appropriate abstraction levels

**Documentation Quality:**
- [ ] Comprehensive README
- [ ] Clear API documentation
- [ ] Contributing guidelines
- [ ] Examples and tutorials

**Testing Practices:**
- [ ] Test coverage evidence
- [ ] Testing strategy clarity
- [ ] CI/CD integration
- [ ] Quality assurance processes

### 2. Community Health (30% weight)

**Maintainer Responsiveness:**
- [ ] Issue response time
- [ ] PR review quality
- [ ] Communication clarity
- [ ] Long-term commitment

**Community Engagement:**
- [ ] Active contributor base
- [ ] Discussion quality
- [ ] Code of conduct presence
- [ ] Inclusive practices

**Governance:**
- [ ] Clear decision-making process
- [ ] Transparent communication
- [ ] Conflict resolution
- [ ] Project sustainability

### 3. Innovation and Best Practices (20% weight)

**Innovative Approaches:**
- [ ] Novel problem-solving
- [ ] Creative architecture
- [ ] Unique features
- [ ] Industry leadership

**Best Practice Examples:**
- [ ] Security practices
- [ ] Performance optimization
- [ ] Accessibility compliance
- [ ] Internationalization

### 4. Category Representation (10% weight)

**Scale Diversity:**
- [ ] Small projects (personal/side projects)
- [ ] Medium projects (team projects)
- [ ] Large projects (enterprise/community)

**Approach Diversity:**
- [ ] Different architectural patterns
- [ ] Various technology stacks
- [ ] Different organizational models
- [ ] Various deployment strategies

## Selection Criteria

### Must Have (Elimination Criteria)
- [ ] Active development (commits in last 6 months)
- [ ] Basic documentation (README, basic docs)
- [ ] Community presence (issues, discussions)
- [ ] License clarity
- [ ] Security awareness (basic practices)

### Should Have (Quality Indicators)
- [ ] Comprehensive documentation
- [ ] Testing practices
- [ ] CI/CD pipeline
- [ ] Contributing guidelines
- [ ] Code of conduct

### Nice to Have (Excellence Indicators)
- [ ] Performance optimization
- [ ] Accessibility compliance
- [ ] Internationalization
- [ ] Advanced security practices
- [ ] Innovative approaches

## Ranking Methodology

### 1. Quantitative Scoring
- Use automated metrics as baseline
- Weight by category importance
- Normalize across categories

### 2. Qualitative Assessment
- Apply human judgment criteria
- Consider context and nuance
- Balance different quality aspects

### 3. Diversity Requirements
- Ensure scale representation
- Maintain approach diversity
- Balance technology stacks
- Consider community models

## Decision Documentation

For each selected project, document:

### Selection Rationale
- Why this project was chosen
- Key strengths and qualities
- Unique or innovative aspects
- Category representation value

### Quality Assessment
- Specific quality indicators observed
- Areas of excellence
- Potential improvement areas
- Overall quality score

### Diversity Contribution
- How this project contributes to diversity
- Scale representation (small/medium/large)
- Approach representation (architecture/technology)
- Community model representation

## Final Output

### Project Shortlist
- 3-5 projects per category (24-40 total)
- Ranked by quality and diversity
- Clear selection rationale
- Quality assessment summary

### Handoff Documentation
- Selection methodology applied
- Quality thresholds used
- Diversity requirements met
- Ready for Phase 2 analysis

## Quality Assurance

### Cross-Validation
- [ ] Multiple reviewers for controversial decisions
- [ ] Cross-reference with automated metrics
- [ ] Validate against selection criteria
- [ ] Ensure diversity requirements met

### Documentation Review
- [ ] Selection rationale is clear
- [ ] Quality assessment is documented
- [ ] Diversity contribution is explained
- [ ] Handoff documentation is complete

This prompt ensures consistent, high-quality project selection while maintaining the diversity and quality standards required for comprehensive analysis.
